{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "[Lee et al 2017](https://www.ijcai.org/proceedings/2017/0289.pdf) architecture\n",
    "\n",
    "<img src=\"images/architecture.png\" alt=\"drawing\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "\n",
    "from nltk import ngrams\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, Flatten, LSTM, Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(sequences, ngram2idx, emb_dim):\n",
    "    sequences = [list((str(idx) for idx in name)) for name in sequences]\n",
    "    model = Word2Vec(sequences, size=emb_dim, window=5, min_count=0, iter=10)\n",
    "    init = np.zeros((len(ngram2idx), emb_dim), dtype=np.float32)\n",
    "    for ngram, idx in ngram2idx.items():\n",
    "        init[idx] = model[str(idx)]\n",
    "    return init\n",
    "\n",
    "\n",
    "def top_k_mod(y_true, y_pred, k=3):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_processed/'\n",
    "name2country = pickle.load(\n",
    "    open(os.path.join(data_dir, 'name2country.p'), 'rb'))\n",
    "country2idx = pickle.load(\n",
    "    open(os.path.join(data_dir, 'country2idx.p'), 'rb'))\n",
    "unigram2idx = pickle.load(\n",
    "    open(os.path.join(data_dir, 'unigram2idx.p'), 'rb'))\n",
    "bigram2idx = pickle.load(\n",
    "    open(os.path.join(data_dir, 'bigram2idx.p'), 'rb'))\n",
    "trigram2idx = pickle.load(\n",
    "    open(os.path.join(data_dir, 'trigram2idx.p'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to preserve order, so dictionaries are not good...\n",
    "tmp = list(name2country.items())\n",
    "tmp = sorted(tmp, key=lambda tmp: tmp[0])\n",
    "all_names, all_countries = [], []\n",
    "for n, c in tmp:\n",
    "    all_names.append(n)\n",
    "    all_countries.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build corpus of ngrams with n=1,2,3\n",
    "unig_corpus = [list((''.join(ng) for ng in ngrams(name, 1)))\n",
    "               for name in all_names]\n",
    "bigr_corpus = [list((''.join(ng) for ng in ngrams(name, 2)))\n",
    "               for name in all_names]\n",
    "trig_corpus = [list((''.join(ng) for ng in ngrams(name, 3)))\n",
    "               for name in all_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical-encoded sequences\n",
    "unig_seq = [list(unigram2idx[gram] for gram in name)\n",
    "            for name in unig_corpus]\n",
    "bigr_seq = [list(bigram2idx[gram] for gram in name)\n",
    "            for name in bigr_corpus]\n",
    "trig_seq = [list(trigram2idx[gram] for gram in name)\n",
    "            for name in trig_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will consider 30 characters per name. We pad sorter names\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "unig_X = np.vstack(pad_sequences(unig_seq, MAX_SEQUENCE_LENGTH))\n",
    "bigr_X = np.vstack(pad_sequences(bigr_seq, MAX_SEQUENCE_LENGTH))\n",
    "trig_X = np.vstack(pad_sequences(trig_seq, MAX_SEQUENCE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
